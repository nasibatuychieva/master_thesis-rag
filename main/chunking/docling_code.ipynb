{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2095bcb7-7e6c-4ea1-a7b6-61f2ec62df9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install docling\n",
    "!pip install -qU pip docling transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf0ef3ac-aa06-4732-ae8d-dd7445d06678",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pyspark.dbutils import DBUtils\n",
    "import re, os\n",
    "\n",
    "def get_repo_root() -> Path:\n",
    "    dbutils = DBUtils(spark)\n",
    "    notebook_path = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "\n",
    "    # Extrahiere /Workspace/Repos/<user>/<repo>\n",
    "    match = re.match(r\"^(\\/Workspace\\/Repos\\/[^\\/]+\\/[^\\/]+)\", notebook_path)\n",
    "    if match:\n",
    "        return Path(match.group(1))\n",
    "    else:\n",
    "        return Path(os.getcwd())\n",
    "\n",
    "repo_root = get_repo_root()\n",
    "print(\"üìÅ Repo root:\", repo_root)\n",
    "\n",
    "# Eine Ebene h√∂her (wie \"cd ..\")\n",
    "parent_path = repo_root.parent\n",
    "\n",
    "# Zwei Ebenen h√∂her\n",
    "two_up = repo_root.parent.parent\n",
    "\n",
    "print(\"‚¨ÜÔ∏è Eine Ebene h√∂her:\", parent_path)\n",
    "print(\"‚¨ÜÔ∏è root:\", parent_path)\n",
    "\n",
    "doc_root = parent_path / \"documents\"\n",
    "out_dir = parent_path / \"out\"\n",
    "product_name = \"Nano 33 BLE\"\n",
    "product_category = \"Nano Family\"\n",
    "file_name  = \"Nano_33_BLE_datasheet.pdf\"\n",
    "\n",
    "pdf_path = doc_root / product_category / product_name / \"Nano_33_BLE_datasheet.pdf\"\n",
    "print(\"‚¨ÜÔ∏è pdf pfad:\",pdf_path)\n",
    "\n",
    "out_path_docling = out_dir / product_category / product_name / \"docling_chunks.jsonl\"\n",
    "print(\"‚¨ÜÔ∏è oout_path_docling:\",out_path_docling)\n",
    "\n",
    "out_path_langchain = out_dir / product_category / product_name / \"langchain_chunks.jsonl\"\n",
    "print(\"‚¨ÜÔ∏è out_path_langchain:\",out_path_langchain)\n",
    "\n",
    "code_path_langchain = parent_path / \"langchain_chunking.py\"\n",
    "print(\"‚¨ÜÔ∏ècode_path_langchain:\",code_path_langchain)\n",
    "\n",
    "code_path_docling= parent_path / \"docling_chunking.py\"\n",
    "print(\"‚¨ÜÔ∏ècode_path_langchain:\",code_path_docling)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4080490-68e9-4231-9d1d-32d077a35fe0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "pdf_options = PdfPipelineOptions()\n",
    "pdf_options.do_ocr = False                    # No OCR - pure text extraction only   # noqa: E501\n",
    "pdf_options.generate_page_images = False      # No page images  # noqa: E501\n",
    "pdf_options.generate_picture_images = False   # Ignore pictures completely  # noqa: E501\n",
    "pdf_options.generate_table_images = False     # Keep tables as text/markdown, not images  # noqa: E501\n",
    "\n",
    "        # Configure format options\n",
    "format_options = {\n",
    "            InputFormat.PDF: PdfFormatOption(\n",
    "                pipeline_options=pdf_options\n",
    "            )\n",
    "        }\n",
    "\n",
    "# Initialize document converter\n",
    "converter = DocumentConverter(\n",
    "            format_options=format_options\n",
    "        )\n",
    "result = converter.convert(pdf_path)\n",
    "doc = result.document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d985edd-e2de-4c10-8af7-41c538254164",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(doc_2.pages)\n",
    "print(doc_2.export_to_markdown()[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c39cde7-ac4a-4e4c-83a8-f1cce4a50b69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from docling_core.transforms.chunker.tokenizer.huggingface import HuggingFaceTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from docling.chunking import HybridChunker\n",
    "\n",
    "EMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "MAX_TOKENS = 800  # set to a small number for illustrative purposes\n",
    "\n",
    "tokenizer = HuggingFaceTokenizer(\n",
    "    tokenizer=AutoTokenizer.from_pretrained(EMBED_MODEL_ID),\n",
    "    max_tokens=MAX_TOKENS,  # optional, by default derived from `tokenizer` for HF case\n",
    ")\n",
    "chunker = HybridChunker(\n",
    "    tokenizer=tokenizer,\n",
    "    merge_peers=True,  # optional, defaults to True\n",
    ")\n",
    "# chunk_iter = chunker.chunk(dl_doc=doc_2)\n",
    "# chunks = list(chunk_iter)\n",
    "# chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fe3dec2-eadc-4f46-8bde-ad8e0c845e0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cleaning-Funktion\n",
    "# ---------------------------\n",
    "def clean_text(t: str) -> str:\n",
    "    if not t:\n",
    "        return \"\"\n",
    "    t = re.sub(r\"(\\w)-\\n(\\w)\", r\"\\1\\2\", t)\n",
    "    t = t.replace(\"\\r\", \"\")\n",
    "    t = re.sub(r\"\\n{2,}\", \"\\n\", t)\n",
    "    t = re.sub(r\"[ \\t]{2,}\", \" \", t)\n",
    "\n",
    "    def noisy(line: str) -> bool:\n",
    "        s = line.strip()\n",
    "        if not s:\n",
    "            return True\n",
    "        non_alpha = sum(1 for ch in s if not ch.isalpha())\n",
    "        return (non_alpha / max(1, len(s))) > 0.6\n",
    "\n",
    "    lines = [ln for ln in t.split(\"\\n\") if not noisy(ln)]\n",
    "    t = \"\\n\".join(lines)\n",
    "    t = re.sub(r\"^(Table|Figure)\\s*\\d+[:.\\-]\\s.*$\", \"\", t, flags=re.IGNORECASE | re.MULTILINE)\n",
    "    t = re.sub(r\"^\\s*\\|.*\\|\\s*$\", \"\", t, flags=re.MULTILINE)\n",
    "    t = re.sub(r\"^\\s*[-=]{3,}\\s*$\", \"\", t, flags=re.MULTILINE)\n",
    "    return t.strip()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a7c35a2-6b4d-4738-afd2-2283e41c7b7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_heading(title: str) -> str:\n",
    "    \"\"\"Entfernt Kapitel-/Abschnitts-Pr√§fixe, Nummern und Deko.\"\"\"\n",
    "    if not title:\n",
    "        return \"\"\n",
    "    s = title.strip().lower()\n",
    "\n",
    "    # \"section 9\", \"chapter 3\", \"kapitel 4\", \"abschnitt 2\" vorne entfernen\n",
    "    s = re.sub(r'^\\s*(section|chapter|kapitel|abschnitt)\\s*\\d+[:.)-]*\\s*', '', s, flags=re.I)\n",
    "\n",
    "    # f√ºhrende Nummerierung wie \"9.\", \"9.1.2\", \"10)\" etc. entfernen\n",
    "    s = re.sub(r'^\\s*\\d+(?:\\.\\d+)*\\s*[:.)-]*\\s*', '', s)\n",
    "\n",
    "    # Deko am Ende weg\n",
    "    s = s.rstrip(' :.-')\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    return s\n",
    "HEADINGS_BLACKLIST_EQ = {\n",
    "    # exakte Matches nach Normalisierung\n",
    "    \"contents\", \"table of contents\", \"toc\",\n",
    "    \"index\", \"references\", \"reference documentation\",\n",
    "    \"company information\", \"company info\",\n",
    "    \"revision history\", \"document history\",\n",
    "    \"legal notice\", \"trademarks\", \"acknowledgements\",\n",
    "    \"glossary\", \"contacts\", \"contact\",\n",
    "    # deutsch\n",
    "    \"inhalt\", \"inhaltsverzeichnis\", \"verzeichnis\",\n",
    "    \"referenzen\", \"referenzdokumentation\",\n",
    "    \"unternehmensinformationen\", \"revision\", \"versionsverlauf\",\n",
    "    \"rechtliche hinweise\", \"marken\", \"danksagungen\", \"glossar\", \"kontakt\",\n",
    "}\n",
    "\n",
    "# substring-Varianten (robuster)\n",
    "HEADINGS_BLACKLIST_CONTAINS = {\n",
    "    \"reference documentation\",\n",
    "    \"referenzdokumentation\",\n",
    "    \"table of contents\",\n",
    "    \"inhaltsverzeichnis\",\n",
    "    \"revision history\",\n",
    "    \"document history\",\n",
    "    \"company information\",\n",
    "}\n",
    "\n",
    "def title_matches_blacklist(title: str) -> bool:\n",
    "    tnorm = normalize_heading(title)\n",
    "    if tnorm in HEADINGS_BLACKLIST_EQ:\n",
    "        return True\n",
    "    return any(key in tnorm for key in HEADINGS_BLACKLIST_CONTAINS)\n",
    "URL_RE = re.compile(r'https?://|www\\.', re.I)\n",
    "\n",
    "def url_ratio(text: str) -> float:\n",
    "    if not text:\n",
    "        return 0.0\n",
    "    urls = len(URL_RE.findall(text))\n",
    "    words = max(1, len(text.split()))\n",
    "    return urls / words\n",
    "\n",
    "def looks_like_link_table(text: str) -> bool:\n",
    "    # viele \"Link =\"-Zeilen oder Markdown-Tabelle\n",
    "    lines = text.splitlines()\n",
    "    link_eq = sum(1 for ln in lines if \"link\" in ln.lower() and \"=\" in ln)\n",
    "    pipes   = sum(1 for ln in lines if ln.count(\"|\") >= 2)\n",
    "    return link_eq >= 2 or pipes >= 6\n",
    "def get_section_title_from_chunk(ch):\n",
    "    hp = getattr(ch, \"hierarchy_path\", None)\n",
    "    if isinstance(hp, list) and hp:\n",
    "        last = hp[-1]\n",
    "        if isinstance(last, dict):\n",
    "            return last.get(\"title\") or \"\"\n",
    "    return \"\"\n",
    "\n",
    "def first_line(text: str) -> str:\n",
    "    return (text or \"\").split(\"\\n\", 1)[0].strip()\n",
    "\n",
    "def should_drop_chunk(ch, ctx_text: str) -> bool:\n",
    "    title_h = get_section_title_from_chunk(ch)\n",
    "    title_f = first_line(ctx_text)\n",
    "\n",
    "    # 1) Titel (hierarchy oder erste Zeile) ‚Äì nach Normalisierung + contains\n",
    "    if title_matches_blacklist(title_h) or title_matches_blacklist(title_f):\n",
    "        return True\n",
    "\n",
    "    # 2) Inhaltliche Heuristik ‚Äì viele Links / Link-Tabelle\n",
    "    if url_ratio(ctx_text) > 0.04 or looks_like_link_table(ctx_text):\n",
    "        # nur droppen, wenn der Titel leicht in die Richtung geht (robust)\n",
    "        if any(k in normalize_heading(title_f) for k in (\"reference\", \"referenz\", \"link\", \"documentation\")) \\\n",
    "           or any(k in normalize_heading(title_h) for k in (\"reference\", \"referenz\", \"link\", \"documentation\")):\n",
    "            return True\n",
    "\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0382c9a5-683b-4ab4-b5f6-657d74ad66e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "out_path_docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf158ded-e7e3-4fe6-abec-cfdc746edef3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "out_path_langchain = out_dir / product_category / product_name / \"langchain_chunks.jsonl\"\n",
    "print(\"‚¨ÜÔ∏è out_path_langchain:\",out_path_langchain)\n",
    "\n",
    "code_path_langchain = parent_path / \"langchain_chunking.py\"\n",
    "print(\"‚¨ÜÔ∏ècode_path_langchain:\",code_path_langchain)\n",
    "\n",
    "code_path_docling= parent_path / \"docling_chunking.py\"\n",
    "print(\"‚¨ÜÔ∏ècode_path_langchain:\",code_path_docling)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d772da9-619a-4ab9-8715-8592fb349b93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def process_pdf(pdf_path: Path, out_dir: Path):\n",
    "    category = pdf_path.parent.parent.name\n",
    "    product  = pdf_path.parent.name\n",
    "\n",
    "    out_path = out_dir / category / \"docling_chunks.jsonl\"\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    #doc = converter.convert(str(pdf_path)).document\n",
    "    raw_chunks = list(chunker.chunk(dl_doc=doc_2))\n",
    "    total_chunks = len(raw_chunks)\n",
    "\n",
    "    records = []\n",
    "    for i, ch in enumerate(raw_chunks):\n",
    "        text_raw = clean_text(ch.text or \"\")\n",
    "        if len(text_raw) < 30:\n",
    "            continue\n",
    "\n",
    "        context = clean_text(chunker.contextualize(chunk=ch))\n",
    "        if len(context.split()) < 25:\n",
    "            continue\n",
    "\n",
    "        if should_drop_chunk(ch, context):  # optional\n",
    "            continue\n",
    "\n",
    "        # section (defensiv)\n",
    "        section = None\n",
    "        hp = getattr(ch, \"hierarchy_path\", None)\n",
    "        if isinstance(hp, list) and hp:\n",
    "            last = hp[-1]\n",
    "            if isinstance(last, dict):\n",
    "                section = last.get(\"title\")\n",
    "\n",
    "        n_tokens = tokenizer.count_tokens(context)\n",
    "        semantic_density = round(n_tokens / max(1, len(context)), 4)\n",
    "\n",
    "        rec = {\n",
    "            \"category\": category,\n",
    "            \"chunk_id\": f\"{pdf_path.stem}::c{i}\",\n",
    "            \"chunk_size\": n_tokens,\n",
    "            \"chunk_type\": \"contextualized\",\n",
    "            \"product\": product,\n",
    "            \"section\": section,\n",
    "            \"semantic_density\": semantic_density,\n",
    "            \"text\": f\"[Product: {product}] [Category: {category}]\\n\\n{context}\",\n",
    "            \"total_chunks\": total_chunks,\n",
    "        }\n",
    "        records.append(rec)\n",
    "\n",
    "    with open(out_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        for r in records:\n",
    "            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"[OK] {len(records)} Chunks hinzugef√ºgt zu: {out_path}\")\n",
    "\n",
    "def iterate_product_docs(doc_root: Path, out_dir: Path):\n",
    "    for pdf_path in doc_root.rglob(\"*.pdf\"):\n",
    "        # erwartet Struktur <root>/<category>/<product>/<file.pdf>\n",
    "        if len(pdf_path.parts) >= 3:\n",
    "            print(f\"üìÇ {pdf_path.parent.parent.name} / {pdf_path.parent.name}\")\n",
    "            process_pdf(pdf_path, out_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2cc8aeb-b7c1-4653-b74f-f392e604dac1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "\n",
    "def get_repo_root() -> Path:\n",
    "    dbutils = DBUtils(spark)\n",
    "    notebook_path = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "\n",
    "    # Extrahiere /Workspace/Repos/<user>/<repo>\n",
    "    match = re.match(r\"^(\\/Workspace\\/Repos\\/[^\\/]+\\/[^\\/]+)\", notebook_path)\n",
    "    if match:\n",
    "        return Path(match.group(1))\n",
    "    else:\n",
    "        return Path(os.getcwd())\n",
    "\n",
    "repo_root = get_repo_root()\n",
    "print(\"üìÅ Repo root:\", repo_root)\n",
    "\n",
    "# Eine Ebene h√∂her (wie \"cd ..\")\n",
    "parent_path = repo_root.parent\n",
    "\n",
    "doc_root = parent_path / \"documents\"\n",
    "out_dir = parent_path / \"out\"\n",
    "# product_name = \"Nano 33 BLE\"\n",
    "# product_category = \"Nano Family\"\n",
    "# file_name  = \"Nano_33_BLE_datasheet.pdf\"\n",
    "\n",
    "print(\"‚¨ÜÔ∏è doc_root:\",doc_root)\n",
    "\n",
    "print(\"‚¨ÜÔ∏è out_dir:\",out_dir)\n",
    "\n",
    "pdf_path = doc_root / product_category / product_name / \"Nano_33_BLE_datasheet.pdf\"\n",
    "print(\"‚¨ÜÔ∏è pdf pfad:\",pdf_path)\n",
    "\n",
    "out_path_docling = out_dir / product_category / product_name / \"docling_chunks.jsonl\"\n",
    "print(\"‚¨ÜÔ∏è oout_path_docling:\",out_path_docling)\n",
    "\n",
    "iterate_product_docs(doc_root, out_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49adffaf-dd4e-4414-b4ac-666f42d45a2a",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"chunk_id\":170},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1761497709122}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "out_path_docling = \"file:/Workspace/Users/nasiba.tuychieva@gea.com/master_thesis-rag/main/out/Nano Family/docling_chunks.jsonl\"\n",
    "df = spark.read.json(out_path_docling)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd855189-7848-45c0-b8c0-f20ddd4861ca",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1761498728198}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "out_path_docling = \"file:/Workspace/Users/nasiba.tuychieva@gea.com/master_thesis-rag/main/out/UNO Family/docling_chunks.jsonl\"\n",
    "df = spark.read.json(out_path_docling)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1366f9f0-4940-4135-b959-68c7ac91afa7",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1761504242638}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "out_path_docling = \"file:/Workspace/Users/nasiba.tuychieva@gea.com/master_thesis-rag/main/out/Education/docling_chunks.jsonl\"\n",
    "df = spark.read.json(out_path_docling)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82ce2d90-eea7-4891-88db-bf7d8e28cc6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install docling\n",
    "%pip install -qU pip docling transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "754778fa-96b3-40e0-b13b-3f4e630373b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.catalog.clearCache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4e021e7-1be7-4518-8bbc-bd82e535e216",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import process_document\n",
    "\n",
    "importlib.reload(process_document)\n",
    "from process_document import get_repo_root, iterate_product_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73e222ef-c58e-44ab-ab7f-12b3c5a7a512",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.unpersist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28b0793e-53db-45c6-9e7e-3ce55b4f9ca4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31826e55-b598-412a-bdba-fbe6f30680eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "root = get_repo_root()\n",
    "print(root)\n",
    "# oder mit eigenem Startpunkt/Markern:\n",
    "# root = get_repo_root(start_path=Path(__file__).parent, markers=['.git', '.hg'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d4a3095-bbd1-4335-966d-b3c0c635e29f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "iterate_product_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31013604-e98c-4510-ab90-96826fa15407",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from process_document import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fcacd8f-f19a-48ee-90a8-b425058e90e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "root = get_repo_root()\n",
    "parent_path = root.parent\n",
    "doc_root = parent_path / \"documents\"\n",
    "out_dir = parent_path / \"out\"\n",
    "print(\"‚¨ÜÔ∏è doc_root:\", doc_root)\n",
    "print(\"‚¨ÜÔ∏è out_dir:\",out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4656cff8-7e0d-45bf-979d-5b09e4e87f91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "root = get_repo_root()\n",
    "parent_path = root.parent\n",
    "doc_root = parent_path / \"documents\"\n",
    "out_dir = parent_path / \"out\"\n",
    "#tokenizer = return_tokenizer()\n",
    "##doc=convert_documents_into_docling_doc(doc_root)\n",
    "#chunker = chunk_documents_with_docling(doc)\n",
    "    \n",
    "for pdf_path in doc_root.rglob(\"*.pdf\"):\n",
    "        # expected struktur: <root>/<category>/<product>/<file.pdf>\n",
    "    if len(pdf_path.parts) >= 3:\n",
    "        print(f\"Processing {pdf_path}\")\n",
    "        print(f\"Processing {pdf_path.parent.parent.name} / {pdf_path.parent.name} / {pdf_path.name}\")\n",
    "        print(f\"Writing {pdf_path.parent.parent.name} / {pdf_path.parent.name} / {pdf_path.name}\")\n",
    "            #process_pdf(pdf_path, out_dir, doc, chunker, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84504a35-0e4e-4644-92b2-bf880ee3a26f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "pdf_path = Path(\"file:/Workspace/Users/nasiba.tuychieva@gea.com/master_thesis-rag/main/documents/MKR Family/MKR IoT Carrier Rev2/ABX00073-datasheet.pdf\")\n",
    "\n",
    "category = pdf_path.parent.parent.name\n",
    "product  = pdf_path.parent.name\n",
    "\n",
    "out_path = out_dir / category / \"docling_chunks.jsonl\"\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c9f3769-07d8-4005-9a40-945b85522c25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3222228-4b0c-43d6-9986-497bae2f07ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "docling_code",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
